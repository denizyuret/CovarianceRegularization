{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "using Knet, AutoGrad, LinearAlgebra, Base.Iterators, Statistics, Random, StatsBase, IterTools, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "ENV[\"COLUMNS\"] = 64\n",
    "ARRAY=Array{Float64} # KnetArray{Float32}\n",
    "UPDATE=true # keep this true (false only useful for checking gradients)\n",
    "BSIZE=1     # keep batchsize=1 until larger ones supported\n",
    "XSIZE=28*28\n",
    "YSIZE=10\n",
    "HSIZE=[64]\n",
    "ALPHA=100.0\n",
    "GAMMA1=0.0001\n",
    "GAMMA2=0.01\n",
    "LAMBDA=0.995\n",
    "ETA=0.1\n",
    "MU0=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minibatched MNIST data:\n",
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "dtrn, dtst = mnistdata(xtype=ARRAY, batchsize=BSIZE)\n",
    "xtrn, ytrn, xtst, ytst = mnist()\n",
    "xtrn = ARRAY(reshape(xtrn,(XSIZE,:)))\n",
    "xtst = ARRAY(reshape(xtst,(XSIZE,:)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition and initialization\n",
    "struct MLP; W; b; μ; B; g1; ∇g1; g2; ∇g2;\n",
    "    function MLP(dims...;α=ALPHA)\n",
    "        h,o = dims[end-1:end]\n",
    "        W = initw.(dims[1:end-1],dims[2:end])\n",
    "        b = initb.(dims[2:end])\n",
    "        μ = initμ(h,o)\n",
    "        B = initB(h,o;α=α)\n",
    "        g1 = initg1(B)\n",
    "        ∇g1 = init∇g1(h)\n",
    "        g2 = initg2(μ)\n",
    "        ∇g2 = init∇g2(h)\n",
    "        new(W, b, μ, B, g1, ∇g1, g2, ∇g2)\n",
    "    end\n",
    "end\n",
    "\n",
    "initw(i,o)=Param(ARRAY(xavier(o,i)))\n",
    "initb(o)=Param(ARRAY(zeros(o,1)))\n",
    "initμ(h,o)=ARRAY(MU0*randn(h,o))\n",
    "initB(h,o;α=ALPHA)=(B = zeros(h,h,o); for i in 1:o, j in 1:h; B[j,j,i] = α; end; ARRAY(B))\n",
    "initg1(B)=[ -sum(logdet.(B[:,:,i] for i in 1:size(B,3))) ]\n",
    "init∇g1(h)=ARRAY(zeros(h,1))\n",
    "initg2(μ)=((d,n)=(0,size(μ,2));for i=1:n-1,j=i+1:n;d-=log(norm(μ[:,i]-μ[:,j])^2);end;[d])\n",
    "init∇g2(h)=ARRAY(zeros(h,1))\n",
    "\n",
    "Base.show(io::IO, m::MLP)=print(IOContext(io,:compact=>true), \"MLP\", (size(m.W[1],2),length.(m.b)...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurevec, predict and loss functions\n",
    "function featurevector(m::MLP,x)\n",
    "    L,y = length(m.W),mat(x)\n",
    "    for l in 1:L-1\n",
    "        y = relu.(m.b[l] .+ m.W[l] * y)\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function (m::MLP)(x) # predict\n",
    "    m.b[end] .+ m.W[end] * featurevector(m,x)\n",
    "end\n",
    "\n",
    "function (m::MLP)(x,labels;γ1=GAMMA1,γ2=GAMMA2) # loss\n",
    "    @assert length(labels)==1 \"Batchsize > 1 not implemented yet.\"\n",
    "    yfeat = featurevector(m,x)\n",
    "    ypred = m.b[end] .+ m.W[end] * yfeat\n",
    "    J = nll(ypred,labels)\n",
    "    g1 = sumlogdet(yfeat,labels,m)\n",
    "    g2 = meandist(yfeat,labels,m)\n",
    "    return J + γ1 * g1 + γ2 * g2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes and returns g1 = ∑ logdet(Ci) = -Σ logdet(Bi)\n",
    "# computes m.∇g1 if training()\n",
    "# updates m.g1 and m.B if update=TRUE\n",
    "function sumlogdet(y,labels,m; λ=LAMBDA, η=ETA, update=UPDATE)\n",
    "    β = labels[1]   # β(n) class label for the nth sample\n",
    "    μ = m.μ[:,β:β]  # μ[β(n)](n-1) exponentially weighted mean of class β(n) before the nth sample\n",
    "    B = m.B[:,:,β]  # B[β(n)](n-1) exponentially weighted inverse covariance matrix of class β(n) before the nth sample\n",
    "    \n",
    "    y0 = y - μ      # ybar[L-1](n) the centralized feature vector\n",
    "    z = B * y0      # unscaled gradient\n",
    "    κ = (1-λ)*λ\n",
    "    ξ = 1 / ((1/(1-λ)) + (y0' * B * y0)[1])  # gradient scaling\n",
    "    A = (1/λ)*(B - z*z'*ξ)  \n",
    "    B2 = A-(1-λ)*η*A*A/(1+(1-λ)*η*tr(A))  # updated inverse covariance matrix  \n",
    "    g1 = m.g1[1] + logdet(B) - logdet(B2) # updated -sumlogdet(B)\n",
    "\n",
    "    if training()  # Store gradient if differentiating\n",
    "        m.∇g1 .= 2 * κ * B2 * y0\n",
    "    end\n",
    "    \n",
    "    if update      # Update state if specified\n",
    "        m.g1[1] = g1\n",
    "        m.B[:,:,β] .= B2\n",
    "    end\n",
    "\n",
    "    return g1\n",
    "end\n",
    "\n",
    "@primitive sumlogdet(y,l,m;o...),dy  dy*m.∇g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes and returns g2 = -Σ log |μi-μj|^2\n",
    "# computes m.∇g2 if training()\n",
    "# updates m.g2 and m.μ if update=TRUE\n",
    "function meandist(y,labels,m; λ=LAMBDA, update=UPDATE)\n",
    "    M = size(m.μ,2) # number of classes\n",
    "    β = labels[1]   # β(n) class label for the nth sample\n",
    "    μ1 = m.μ[:,β:β] # μ[β(n)](n-1) exponentially weighted mean of class β(n) before the nth sample\n",
    "    μ2 = λ * μ1 + (1-λ) * y   # updated mean\n",
    "    g2 = 0\n",
    "    if training(); m.∇g2 .= 0; end\n",
    "    for k=1:M\n",
    "        if (k!=β)\n",
    "            olddist = norm(m.μ[:,k:k]-μ1)^2\n",
    "            newdist = norm(m.μ[:,k:k]-μ2)^2\n",
    "            g2 = g2 + log(olddist) - log(newdist)\n",
    "            if training()\n",
    "                m.∇g2 .+= (2 * (1-λ) / newdist) * (m.μ[:,k:k]-μ2)\n",
    "            end\n",
    "        end\n",
    "    end    \n",
    "    if update\n",
    "        m.g2[1] = g2\n",
    "        m.μ[:,β:β] .= μ2\n",
    "    end\n",
    "    return g2\n",
    "end\n",
    "\n",
    "@primitive meandist(y,l,m;o...),dy  dy*m.∇g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x |> summary = \"28×28×1×1 Array{Float64,4}\"\n",
      "labels = UInt8[0x05]\n",
      "(y = featurevector(m, x)) |> summary = \"64×1 Array{Float64,2}\"\n",
      "(scores = m(x)) |> summary = \"10×1 Array{Float64,2}\"\n",
      "J = nll(scores, labels) = 2.4778561096154585\n",
      "g1 = sumlogdet(y, labels, m) = -2945.9880482939625\n",
      "g2 = meandist(y, labels, m) = -35.75083284918922\n",
      "J + GAMMA1 * g1 + GAMMA2 * g2 = -30.557107658243087\n",
      "m(x, labels) = -30.557107658243087\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: check model functions\n",
    "UPDATE=false\n",
    "(x,labels) = first(dtrn)\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "@show x |> summary\n",
    "@show labels\n",
    "@show (y = featurevector(m,x)) |> summary\n",
    "@show (scores = m(x)) |> summary\n",
    "@show J=nll(scores,labels)\n",
    "@show g1=sumlogdet(y,labels,m)\n",
    "@show g2=meandist(y,labels,m)\n",
    "@show J + GAMMA1 * g1 + GAMMA2 * g2\n",
    "@show m(x,labels)\n",
    "UPDATE=true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#= In[129]:8 =# @gcheck(sumlogdet(py, labels, m)) = true\n",
      "#= In[129]:9 =# @gcheck(meandist(py, labels, m)) = true\n",
      "#= In[129]:10 =# @gcheck(nll(m(x), labels)) = true\n",
      "#= In[129]:11 =# @gcheck(m(x, labels)) = true\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: check gradients\n",
    "using AutoGrad: @gcheck, gcheck\n",
    "(x,labels) = first(dtrn)\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "y = featurevector(m,x)\n",
    "py = Param(y)\n",
    "UPDATE=false\n",
    "@show @gcheck sumlogdet(py,labels,m)\n",
    "@show @gcheck meandist(py,labels,m)\n",
    "@show @gcheck nll(m(x),labels)\n",
    "@show @gcheck m(x,labels)\n",
    "UPDATE=true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.96e+00  100.00%┣████████┫ 10000/10000 [00:28/00:28, 362.85i/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(acc = 0.919, nll = 0.27138646039786907, g1 = -595.6611794864707, g2 = -235.20288970750443)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 3: train one epoch with regularization\n",
    "Random.seed!(1)\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "GAMMA1,GAMMA2=0.01,0.1\n",
    "progress!(adam(m,dtst))\n",
    "(acc=accuracy(m,dtst),nll=nll(m(xtst),ytst),g1=initg1(m.B)[1],g2=initg2(m.μ)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.56e-05  100.00%┣█████████┫ 10000/10000 [00:29/00:29, 347.50i/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(acc = 0.9198, nll = 0.2600133985319897, g1 = -647.7278184729371, g2 = -232.03334179923695)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 4: train one epoch without regularization\n",
    "Random.seed!(1)\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "GAMMA1,GAMMA2 = 0,0\n",
    "progress!(adam(m,dtst))\n",
    "(acc=accuracy(m,dtst),nll=nll(m(xtst),ytst),g1=initg1(m.B)[1],g2=initg2(m.μ)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(7=>10,4=>11,9=>11,10=>13,2=>6,3=>11,5=>5,8=>8,6=>11,1=>14)\n",
      "6.89e-01  100.00%┣██████████████▉┫ 100/100 [00:32/00:32, 3.09i/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.689, 21)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 5: run to convergence with 100 instances, no regularization\n",
    "Random.seed!(1)\n",
    "d100 = take(dtrn,100)\n",
    "countmap([Int(y[1]) for (x,y) in d100]) |> println\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "GAMMA1,GAMMA2 = 0,0\n",
    "a = collect(progress((adam!(m,d100);accuracy(m(xtst),ytst)) for i in 1:100))\n",
    "findmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "goldensection(f,n;kwargs) => (fmin,xmin)\n",
       "\\end{verbatim}\n",
       "Find the minimum of \\texttt{f} using concurrent golden section search in \\texttt{n} dimensions. See \\texttt{Knet.goldensection\\_demo()} for an example.\n",
       "\n",
       "\\texttt{f} is a function from a \\texttt{Vector\\{Float64\\}} of length \\texttt{n} to a \\texttt{Number}.  It can return \\texttt{NaN} for out of range inputs.  Goldensection will always start with a zero vector as the initial input to \\texttt{f}, and the initial step size will be 1 in each dimension.  The user should define \\texttt{f} to scale and shift this input range into a vector meaningful for their application. For positive inputs like learning rate or hidden size, you can use a transformation such as \\texttt{x0*exp(x)} where \\texttt{x} is a value \\texttt{goldensection} passes to \\texttt{f} and \\texttt{x0} is your initial guess for this value. This will effectively start the search at \\texttt{x0}, then move with multiplicative steps.\n",
       "\n",
       "I designed this algorithm combining ideas from \\href{http://apps.nrbook.com/empanel/index.html?pg=492}{Golden Section Search} and \\href{https://en.wikipedia.org/wiki/Hill_climbing}{Hill Climbing Search}. It essentially runs golden section search concurrently in each dimension, picking the next step based on estimated gain.\n",
       "\n",
       "\\section{Keyword arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{dxmin=0.1}: smallest step size.\n",
       "\n",
       "\n",
       "\\item \\texttt{accel=φ}: acceleration rate. Golden ratio \\texttt{φ=1.618...} is best.\n",
       "\n",
       "\n",
       "\\item \\texttt{verbose=false}: use \\texttt{true} to print individual steps.\n",
       "\n",
       "\n",
       "\\item \\texttt{history=[]}: cache of \\texttt{[(x,f(x)),...]} function evaluations.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "goldensection(f,n;kwargs) => (fmin,xmin)\n",
       "```\n",
       "\n",
       "Find the minimum of `f` using concurrent golden section search in `n` dimensions. See `Knet.goldensection_demo()` for an example.\n",
       "\n",
       "`f` is a function from a `Vector{Float64}` of length `n` to a `Number`.  It can return `NaN` for out of range inputs.  Goldensection will always start with a zero vector as the initial input to `f`, and the initial step size will be 1 in each dimension.  The user should define `f` to scale and shift this input range into a vector meaningful for their application. For positive inputs like learning rate or hidden size, you can use a transformation such as `x0*exp(x)` where `x` is a value `goldensection` passes to `f` and `x0` is your initial guess for this value. This will effectively start the search at `x0`, then move with multiplicative steps.\n",
       "\n",
       "I designed this algorithm combining ideas from [Golden Section Search](http://apps.nrbook.com/empanel/index.html?pg=492) and [Hill Climbing Search](https://en.wikipedia.org/wiki/Hill_climbing). It essentially runs golden section search concurrently in each dimension, picking the next step based on estimated gain.\n",
       "\n",
       "# Keyword arguments\n",
       "\n",
       "  * `dxmin=0.1`: smallest step size.\n",
       "  * `accel=φ`: acceleration rate. Golden ratio `φ=1.618...` is best.\n",
       "  * `verbose=false`: use `true` to print individual steps.\n",
       "  * `history=[]`: cache of `[(x,f(x)),...]` function evaluations.\n"
      ],
      "text/plain": [
       "\u001b[36m  goldensection(f,n;kwargs) => (fmin,xmin)\u001b[39m\n",
       "\n",
       "  Find the minimum of \u001b[36mf\u001b[39m using concurrent golden section search\n",
       "  in \u001b[36mn\u001b[39m dimensions. See \u001b[36mKnet.goldensection_demo()\u001b[39m for an\n",
       "  example.\n",
       "\n",
       "  \u001b[36mf\u001b[39m is a function from a \u001b[36mVector{Float64}\u001b[39m of length \u001b[36mn\u001b[39m to a\n",
       "  \u001b[36mNumber\u001b[39m. It can return \u001b[36mNaN\u001b[39m for out of range inputs.\n",
       "  Goldensection will always start with a zero vector as the\n",
       "  initial input to \u001b[36mf\u001b[39m, and the initial step size will be 1 in\n",
       "  each dimension. The user should define \u001b[36mf\u001b[39m to scale and shift\n",
       "  this input range into a vector meaningful for their\n",
       "  application. For positive inputs like learning rate or\n",
       "  hidden size, you can use a transformation such as \u001b[36mx0*exp(x)\u001b[39m\n",
       "  where \u001b[36mx\u001b[39m is a value \u001b[36mgoldensection\u001b[39m passes to \u001b[36mf\u001b[39m and \u001b[36mx0\u001b[39m is your\n",
       "  initial guess for this value. This will effectively start\n",
       "  the search at \u001b[36mx0\u001b[39m, then move with multiplicative steps.\n",
       "\n",
       "  I designed this algorithm combining ideas from Golden\n",
       "  Section Search\n",
       "  (http://apps.nrbook.com/empanel/index.html?pg=492) and Hill\n",
       "  Climbing Search\n",
       "  (https://en.wikipedia.org/wiki/Hill_climbing). It\n",
       "  essentially runs golden section search concurrently in each\n",
       "  dimension, picking the next step based on estimated gain.\n",
       "\n",
       "\u001b[1m  Keyword arguments\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •    \u001b[36mdxmin=0.1\u001b[39m: smallest step size.\n",
       "\n",
       "    •    \u001b[36maccel=φ\u001b[39m: acceleration rate. Golden ratio\n",
       "        \u001b[36mφ=1.618...\u001b[39m is best.\n",
       "\n",
       "    •    \u001b[36mverbose=false\u001b[39m: use \u001b[36mtrue\u001b[39m to print individual steps.\n",
       "\n",
       "    •    \u001b[36mhistory=[]\u001b[39m: cache of \u001b[36m[(x,f(x)),...]\u001b[39m function\n",
       "        evaluations."
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc goldensection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.006737946999085467, 0.006737946999085467, 0.6938, 87)\n",
      "(0.01831563888873418, 0.006737946999085467, 0.6952, 30)\n",
      "(0.01831563888873418, 0.01831563888873418, 0.6974, 61)\n",
      "(0.01831563888873418, 0.09236880077985307, 0.6941, 43)\n",
      "(0.09236880077985307, 0.01831563888873418, 0.6953, 27)\n",
      "(0.01831563888873418, 0.03398058281256863, 0.6993, 53)\n",
      "(0.006737946999085467, 0.03398058281256863, 0.6936, 26)\n",
      "(0.03398058281256863, 0.03398058281256863, 0.6974, 40)\n",
      "(0.012500757815767668, 0.03398058281256863, 0.6975, 45)\n",
      "(0.01831563888873418, 0.049787068367863944, 0.6977, 22)\n",
      "(0.02319236794081144, 0.03398058281256863, 0.6955, 45)\n",
      "(0.015829214397789157, 0.03398058281256863, 0.6984, 50)\n",
      "(0.01831563888873418, 0.026835383330071433, 0.6976, 46)\n",
      "(0.01831563888873418, 0.03931819156550566, 0.6957, 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.6993, [1.0, 1.61803])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 6: find best γ1,γ2 for 100 instances\n",
    "function evalgammas(gammas)\n",
    "    global GAMMA1,GAMMA2\n",
    "    GAMMA1 = exp(gammas[1]-5)\n",
    "    GAMMA2 = exp(gammas[2]-5)\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,d100); accuracy(m(xtst),ytst)) for i in 1:100 ]\n",
    "    println((GAMMA1,GAMMA2,findmax(a)...))\n",
    "    -maximum(a)\n",
    "end\n",
    "\n",
    "# best = (0.01831563888873418, 0.03398058281256863, 0.6993, 53)\n",
    "goldensection(evalgammas,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.539992976248485e-5, 4.539992976248485e-5, 0.692, 95)\n",
      "(0.00012340980408667956, 4.539992976248485e-5, 0.6939, 98)\n",
      "(0.00012340980408667956, 0.00012340980408667956, 0.693, 94)\n",
      "(0.0006223760840237344, 4.539992976248485e-5, 0.6899, 97)\n",
      "(0.00022895936598912205, 4.539992976248485e-5, 0.6882, 94)\n",
      "(8.422944361104595e-5, 4.539992976248485e-5, 0.6928, 87)\n",
      "(0.00015626894596847642, 4.539992976248485e-5, 0.6879, 11)\n",
      "(0.00010665640764946391, 4.539992976248485e-5, 0.693, 93)\n",
      "(0.00012340980408667956, 2.4470702097434435e-5, 0.6885, 100)\n",
      "(0.00012340980408667956, 6.651826484109067e-5, 0.6927, 98)\n",
      "(0.00012340980408667956, 3.58535498068023e-5, 0.6879, 21)\n",
      "(0.00012340980408667956, 5.253126896933724e-5, 0.6915, 99)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.6939, [1.0, 0.0])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 6a: find best γ1,γ2 for 100 instances starting from small gamma\n",
    "## Note: 100 iters do not seem enough for convergence with small gamma.\n",
    "function evalgammas(gammas)\n",
    "    global GAMMA1,GAMMA2\n",
    "    GAMMA1 = exp(gammas[1]-10)\n",
    "    GAMMA2 = exp(gammas[2]-10)\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,d100); accuracy(m(xtst),ytst)) for i in 1:100 ]\n",
    "    println((GAMMA1,GAMMA2,findmax(a)...))\n",
    "    -maximum(a)\n",
    "end\n",
    "\n",
    "# best = (0.00012340980408667956, 4.539992976248485e-5, 0.6939, 98)\n",
    "goldensection(evalgammas,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 0.6901, 41)\n",
      "(2.718281828459045, 1.0, 0.6563, 36)\n",
      "(1.0, 2.718281828459045, 0.6751, 72)\n",
      "(0.5390030827240446, 1.0, 0.6897, 83)\n",
      "(1.0, 0.5390030827240446, 0.6786, 54)\n",
      "(1.0, 1.465162285252178, 0.6904, 94)\n",
      "(1.465162285252178, 1.465162285252178, 0.6854, 62)\n",
      "(0.78972698844193, 1.465162285252178, 0.6859, 75)\n",
      "(1.1570781991108985, 1.465162285252178, 0.6862, 67)\n",
      "(1.0, 1.8552769586143045, 0.6814, 77)\n",
      "(1.0, 1.2662603844563072, 0.6893, 88)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.6904, [0.0, 0.381966])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 6b: find best γ1,γ2 for 100 instances starting from large gamma\n",
    "function evalgammas(gammas)\n",
    "    global GAMMA1,GAMMA2\n",
    "    GAMMA1 = exp(gammas[1])\n",
    "    GAMMA2 = exp(gammas[2])\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,d100); accuracy(m(xtst),ytst)) for i in 1:100 ]\n",
    "    println((GAMMA1,GAMMA2,findmax(a)...))\n",
    "    -maximum(a)\n",
    "end\n",
    "\n",
    "# best = (1.0, 1.465162285252178, 0.6904, 94)\n",
    "goldensection(evalgammas,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(7=>117,4=>105,9=>100,10=>97,2=>99,3=>93,5=>92,8=>87,6=>94,1=>116)\n",
      "8.85e-01  100.00%┣██████████████▉┫ 100/100 [05:16/05:16, 3.16s/i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8885, 13)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 7: run to convergence with 1000 instances, no regularization\n",
    "Random.seed!(1)\n",
    "d1000 = take(dtrn,1000)\n",
    "countmap([Int(y[1]) for (x,y) in d1000]) |> println\n",
    "m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "GAMMA1,GAMMA2,UPDATE = 0,0,false\n",
    "a = collect(progress((adam!(m,d1000);accuracy(m(xtst),ytst)) for i in 1:100))\n",
    "UPDATE=true\n",
    "findmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01831563888873418, 0.01831563888873418, 0.8774, 23)\n",
      "(0.049787068367863944, 0.01831563888873418, 0.8817, 17)\n",
      "(0.049787068367863944, 0.049787068367863944, 0.8767, 16)\n",
      "(0.2510844326764283, 0.01831563888873418, 0.8771, 9)\n",
      "(0.049787068367863944, 0.009872185823088117, 0.8792, 14)\n",
      "(0.09236880077985307, 0.01831563888873418, 0.8793, 15)\n",
      "(0.049787068367863944, 0.026835383330071433, 0.8791, 18)\n",
      "(0.049787068367863944, 0.01446435434098994, 0.8763, 19)\n",
      "(0.049787068367863944, 0.021192626460942082, 0.876, 10)\n",
      "(0.03398058281256863, 0.01831563888873418, 0.8787, 12)\n",
      "(0.06304339233244385, 0.01831563888873418, 0.8748, 22)\n",
      "(0.043028265856292554, 0.01831563888873418, 0.8784, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.8817, [1.0, 0.0])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 8: find best γ1,γ2 for 1000 instances\n",
    "function evalgammas(gammas)\n",
    "    global GAMMA1,GAMMA2\n",
    "    GAMMA1 = exp(gammas[1]-4)\n",
    "    GAMMA2 = exp(gammas[2]-4)\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,d1000); accuracy(m(xtst),ytst)) for i in 1:30 ]\n",
    "    println((GAMMA1,GAMMA2,findmax(a)...))\n",
    "    -maximum(a)\n",
    "end\n",
    "\n",
    "# best = (0.049787068367863944, 0.01831563888873418, 0.8817, 17)\n",
    "goldensection(evalgammas,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1253517471925912e-7, 1.1253517471925912e-7, 0.8883, 15)\n",
      "(3.059023205018258e-7, 1.1253517471925912e-7, 0.8885, 14)\n",
      "(3.059023205018258e-7, 3.059023205018258e-7, 0.8875, 14)\n",
      "(3.059023205018258e-7, 6.065680608856974e-8, 0.888, 14)\n",
      "(1.542716072978916e-6, 1.1253517471925912e-7, 0.8875, 14)\n",
      "(3.059023205018258e-7, 1.648822937629228e-7, 0.8873, 16)\n",
      "(3.059023205018258e-7, 8.88720646248269e-8, 0.8889, 14)\n",
      "(3.059023205018258e-7, 7.680731059760373e-8, 0.889, 14)\n",
      "(5.675335268136856e-7, 7.680731059760373e-8, 0.8874, 14)\n",
      "(2.0878391669027646e-7, 7.680731059760373e-8, 0.8882, 15)\n",
      "(3.873519899647185e-7, 7.680731059760373e-8, 0.889, 14)\n",
      "(2.6437480261652313e-7, 7.680731059760373e-8, 0.8883, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.889, [1.0, -0.381966])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 8a: find best γ1,γ2 for 1000 instances starting from small gamma\n",
    "function evalgammas(gammas)\n",
    "    global GAMMA1,GAMMA2\n",
    "    GAMMA1 = exp(gammas[1]-16)\n",
    "    GAMMA2 = exp(gammas[2]-16)\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,d1000); accuracy(m(xtst),ytst)) for i in 1:30 ]\n",
    "    println((GAMMA1,GAMMA2,findmax(a)...))\n",
    "    -maximum(a)\n",
    "end\n",
    "\n",
    "# best = (3.873519899647185e-7, 7.680731059760373e-8, 0.889, 14)\n",
    "goldensection(evalgammas,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n = 32, γ = 0, acc = 0.5578)\n",
      "(n = 32, γ = 0.01, acc = 0.5632)\n",
      "(n = 64, γ = 0, acc = 0.6832)\n",
      "(n = 64, γ = 0.01, acc = 0.6837)\n",
      "(n = 128, γ = 0, acc = 0.7236)\n",
      "(n = 128, γ = 0.01, acc = 0.7237)\n",
      "(n = 256, γ = 0, acc = 0.798)\n",
      "(n = 256, γ = 0.01, acc = 0.7995)\n",
      "(n = 512, γ = 0, acc = 0.8546)\n",
      "(n = 512, γ = 0.01, acc = 0.8507)\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1mthrow_complex_domainerror\u001b[22m\u001b[1m(\u001b[22m::Symbol, ::Float64\u001b[1m)\u001b[22m at \u001b[1m./math.jl:31\u001b[22m\n",
      " [2] \u001b[1mlog\u001b[22m\u001b[1m(\u001b[22m::Float64\u001b[1m)\u001b[22m at \u001b[1m./special/log.jl:285\u001b[22m\n",
      " [3] \u001b[1mlogdet\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,2}\u001b[1m)\u001b[22m at \u001b[1m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/generic.jl:1336\u001b[22m\n",
      " [4] \u001b[1m#sumlogdet#529\u001b[22m\u001b[1m(\u001b[22m::Float64, ::Float64, ::Bool, ::Function, ::Array{Float64,2}, ::Array{UInt8,1}, ::MLP\u001b[1m)\u001b[22m at \u001b[1m./In[122]:15\u001b[22m\n",
      " [5] \u001b[1msumlogdet\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,2}, ::Array{UInt8,1}, ::MLP\u001b[1m)\u001b[22m at \u001b[1m./In[122]:5\u001b[22m\n",
      " [6] \u001b[1m#forw#1\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::Function, ::AutoGrad.Result{Array{Float64,2}}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/AutoGrad/src/core.jl:66\u001b[22m\n",
      " [7] \u001b[1mforw\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/AutoGrad/src/core.jl:65\u001b[22m [inlined]\n",
      " [8] \u001b[1m#sumlogdet#554\u001b[22m at \u001b[1m./none:0\u001b[22m [inlined]\n",
      " [9] \u001b[1msumlogdet\u001b[22m\u001b[1m(\u001b[22m::AutoGrad.Result{Array{Float64,2}}, ::Array{UInt8,1}, ::MLP\u001b[1m)\u001b[22m at \u001b[1m./none:0\u001b[22m\n",
      " [10] \u001b[1m#call#528\u001b[22m\u001b[1m(\u001b[22m::Int64, ::Int64, ::MLP, ::Array{Float64,4}, ::Array{UInt8,1}\u001b[1m)\u001b[22m at \u001b[1m./In[121]:19\u001b[22m\n",
      " [11] \u001b[1m(::MLP)\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,4}, ::Array{UInt8,1}\u001b[1m)\u001b[22m at \u001b[1m./In[121]:15\u001b[22m\n",
      " [12] \u001b[1m(::getfield(Knet, Symbol(\"##664#665\")){Knet.Minimize{Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}},Tuple{Array{Float64,4},Array{UInt8,1}}})\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/AutoGrad/src/core.jl:197\u001b[22m\n",
      " [13] \u001b[1m#differentiate#3\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::Function\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/AutoGrad/src/core.jl:144\u001b[22m\n",
      " [14] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/AutoGrad/src/core.jl:135\u001b[22m\n",
      " [15] \u001b[1miterate\u001b[22m\u001b[1m(\u001b[22m::Knet.Minimize{Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}, ::Tuple{Int64,Int64}\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/Knet/src/train.jl:24\u001b[22m\n",
      " [16] \u001b[1m#adam!#773\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::MLP, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/Knet/src/update.jl:409\u001b[22m\n",
      " [17] \u001b[1madam!\u001b[22m\u001b[1m(\u001b[22m::MLP, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/dev/Knet/src/update.jl:409\u001b[22m\n",
      " [18] \u001b[1m(::getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}})\u001b[22m\u001b[1m(\u001b[22m::Int64\u001b[1m)\u001b[22m at \u001b[1m./none:0\u001b[22m\n",
      " [19] \u001b[1miterate\u001b[22m at \u001b[1m./generator.jl:47\u001b[22m [inlined]\n",
      " [20] \u001b[1mcollect_to!\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}, ::Int64, ::Int64\u001b[1m)\u001b[22m at \u001b[1m./array.jl:651\u001b[22m\n",
      " [21] \u001b[1mcollect_to_with_first!\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,1}, ::Float64, ::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}, ::Int64\u001b[1m)\u001b[22m at \u001b[1m./array.jl:630\u001b[22m\n",
      " [22] \u001b[1mcollect\u001b[22m\u001b[1m(\u001b[22m::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}\u001b[1m)\u001b[22m at \u001b[1m./array.jl:611\u001b[22m\n",
      " [23] top-level scope at \u001b[1mIn[194]:10\u001b[22m\n",
      " [24] \u001b[1meval\u001b[22m at \u001b[1m./boot.jl:328\u001b[22m [inlined]\n",
      " [25] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218\u001b[22m\n",
      " [26] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/IJulia/gI2uA/src/execute_request.jl:67\u001b[22m\n",
      " [27] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m./essentials.jl:742\u001b[22m [inlined]\n",
      " [28] \u001b[1minvokelatest\u001b[22m at \u001b[1m./essentials.jl:741\u001b[22m [inlined]\n",
      " [29] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/IJulia/gI2uA/src/eventloop.jl:8\u001b[22m\n",
      " [30] \u001b[1m(::getfield(IJulia, Symbol(\"##15#18\")))\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m./task.jl:259\u001b[22m\n"
     ]
    },
    {
     "ename": "DomainError",
     "evalue": "DomainError with -1.0:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError with -1.0:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
      "",
      "Stacktrace:",
      " [1] #differentiate#3(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::Function) at /home/ec2-user/.julia/dev/AutoGrad/src/core.jl:148",
      " [2] differentiate(::Function) at /home/ec2-user/.julia/dev/AutoGrad/src/core.jl:135",
      " [3] iterate(::Knet.Minimize{Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}, ::Tuple{Int64,Int64}) at /home/ec2-user/.julia/dev/Knet/src/train.jl:24",
      " [4] #adam!#773(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::MLP, ::Vararg{Any,N} where N) at /home/ec2-user/.julia/dev/Knet/src/update.jl:409",
      " [5] adam!(::MLP, ::Vararg{Any,N} where N) at /home/ec2-user/.julia/dev/Knet/src/update.jl:409",
      " [6] (::getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}})(::Int64) at ./none:0",
      " [7] iterate at ./generator.jl:47 [inlined]",
      " [8] collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}, ::Int64, ::Int64) at ./array.jl:651",
      " [9] collect_to_with_first!(::Array{Float64,1}, ::Float64, ::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}, ::Int64) at ./array.jl:630",
      " [10] collect(::Base.Generator{UnitRange{Int64},getfield(Main, Symbol(\"##671#672\")){Base.Iterators.Take{Knet.Data{Tuple{Array{Float64,4},Array{UInt8,1}}}}}}) at ./array.jl:611",
      " [11] top-level scope at In[194]:10"
     ]
    }
   ],
   "source": [
    "# Experiment 9: compute learning curve\n",
    "# Hyperparameter optimization failed, using γ1=γ2=0.01 as default\n",
    "# Compare with/without regularization for various dataset sizes\n",
    "# 1. Regularization has a slight advantage for small sizes (may be more significant with hyperparam optimization)\n",
    "# 2. The advantage reduces, disappears as dataset size gets bigger\n",
    "# 3. We get a negative log problem at n=1024\n",
    "results9 = Dict()\n",
    "for p in 5:15, g in (0,0.01)\n",
    "    data = take(dtrn,2^p)\n",
    "    GAMMA1 = GAMMA2 = g\n",
    "    Random.seed!(1)\n",
    "    m = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "    a = [ (adam!(m,data); accuracy(m(xtst),ytst)) for i in 1:100 ]\n",
    "    println((n=2^p,γ=g,acc=maximum(a)))\n",
    "    results9[(n=2^p,γ=g)] = a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= Learning curve:\n",
    "(n = 32, γ = 0, acc = 0.5578)\n",
    "(n = 32, γ = 0.01, acc = 0.5632)\n",
    "(n = 64, γ = 0, acc = 0.6832)\n",
    "(n = 64, γ = 0.01, acc = 0.6837)\n",
    "(n = 128, γ = 0, acc = 0.7236)\n",
    "(n = 128, γ = 0.01, acc = 0.7237)\n",
    "(n = 256, γ = 0, acc = 0.798)\n",
    "(n = 256, γ = 0.01, acc = 0.7995)\n",
    "(n = 512, γ = 0, acc = 0.8546)\n",
    "(n = 512, γ = 0.01, acc = 0.8507)\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.55e-01  100.00%┣█████████████████┫ 60/60 [04:04/04:04, 4.07s/i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60-element Array{Float64,1}:\n",
       " 0.8507\n",
       " 0.8802\n",
       " 0.893 \n",
       " 0.8963\n",
       " 0.9023\n",
       " 0.9029\n",
       " 0.9087\n",
       " 0.9214\n",
       " 0.9135\n",
       " 0.9283\n",
       " 0.9229\n",
       " 0.9178\n",
       " 0.9351\n",
       " ⋮     \n",
       " 0.9391\n",
       " 0.9518\n",
       " 0.9598\n",
       " 0.9606\n",
       " 0.9601\n",
       " 0.9562\n",
       " 0.9547\n",
       " 0.9605\n",
       " 0.9518\n",
       " 0.956 \n",
       " 0.9493\n",
       " 0.9547"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 10: Compute training curve with no regularization\n",
    "Random.seed!(1)\n",
    "EPOCHS, TESTFREQ = 1, 1000\n",
    "GAMMA1, GAMMA2, UPDATE = 0, 0, false\n",
    "m0 = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "r0 = collect(progress(accuracy(m0(xtst),ytst) for z in \n",
    "             takenth(adam(m0,repeat(dtrn,EPOCHS)),TESTFREQ)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.51e-01  100.00%┣█████████████████┫ 60/60 [04:02/04:02, 4.04s/i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60-element Array{Float64,1}:\n",
       " 0.8483\n",
       " 0.8783\n",
       " 0.8841\n",
       " 0.8974\n",
       " 0.8998\n",
       " 0.9069\n",
       " 0.9049\n",
       " 0.9212\n",
       " 0.9187\n",
       " 0.9303\n",
       " 0.9244\n",
       " 0.924 \n",
       " 0.9325\n",
       " ⋮     \n",
       " 0.9514\n",
       " 0.9562\n",
       " 0.9597\n",
       " 0.9642\n",
       " 0.9552\n",
       " 0.9568\n",
       " 0.9531\n",
       " 0.9542\n",
       " 0.9563\n",
       " 0.9563\n",
       " 0.946 \n",
       " 0.9506"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment 11: Compute training curve with regularization\n",
    "Random.seed!(1)\n",
    "EPOCHS, TESTFREQ = 1, 1000\n",
    "GAMMA1, GAMMA2, UPDATE = 0.01, 0.01, true\n",
    "m1 = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "r1 = collect(progress(accuracy(m1(xtst),ytst) for z in \n",
    "             takenth(adam(m1,repeat(dtrn,EPOCHS)),TESTFREQ)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.49e-01  100.00%┣█████████████████┫ 60/60 [04:25/04:25, 4.42s/i]\n"
     ]
    }
   ],
   "source": [
    "# Experiment 12: Compute training curve with regularization after an initial period\n",
    "Random.seed!(1)\n",
    "EPOCHS, TESTFREQ = 1, 1000\n",
    "GAMMA1, GAMMA2, UPDATE = 0, 0, false\n",
    "m2 = MLP(XSIZE,HSIZE...,YSIZE)\n",
    "r2 = collect(progress(\n",
    "        (a=accuracy(m2(xtst),ytst); if a>0.9; global GAMMA1,GAMMA2,UPDATE=0.01,0.01,true; end; a)\n",
    "        for z in takenth(adam(m2,repeat(dtrn,EPOCHS)),TESTFREQ)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot training curves\n",
    "Plots.default(fmt=:png,ls=:auto,legend=:bottomright)\n",
    "plot([r0 r1 r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
