{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "using Knet, AutoGrad, LinearAlgebra, Base.Iterators, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "ARRAY=Array{Float64} # KnetArray{Float32}\n",
    "BSIZE=1\n",
    "XSIZE=28*28\n",
    "YSIZE=10\n",
    "HSIZE=64\n",
    "ALPHA=100.0\n",
    "GAMMA=0.0001\n",
    "LAMBDA=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading MNIST...\n",
      "└ @ Main /kuacc/users/dyuret/.julia/dev/Knet/data/mnist.jl:33\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data:\n",
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "dtrn, dtst = mnistdata(xtype=ARRAY, batchsize=BSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initB (generic function with 1 method)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model definition and initialization\n",
    "struct TwoLayerMLP; w1; b1; w2; b2; μ; B; g; ∇g; end\n",
    "\n",
    "TwoLayerMLP(i,h,o;α=ALPHA)=TwoLayerMLP(\n",
    "    initw(i,h),initb(h),\n",
    "    initw(h,o),initb(o),\n",
    "    initμ(h,o),\n",
    "    initB(h,o,α=α),\n",
    "    initg(h,o,α=α), init∇g(h,o)    \n",
    ")\n",
    "\n",
    "initw(i,o)=Param(ARRAY(xavier(o,i)))\n",
    "initb(o)=Param(ARRAY(zeros(o,1)))\n",
    "initμ(h,o)=ARRAY(zeros(h,o))\n",
    "init∇g(h,o)=ARRAY(zeros(h,1))\n",
    "initg(h,o;α=ALPHA)=[-h*o*log(α)]\n",
    "\n",
    "function initB(h,o;α=ALPHA)\n",
    "    B = zeros(h,h,o)\n",
    "    for i in 1:o, j in 1:h\n",
    "        B[j,j,i] = α\n",
    "    end\n",
    "    return ARRAY(B)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and loss functions\n",
    "function (m::TwoLayerMLP)(x) # predict\n",
    "    m.b2 .+ m.w2 * relu.(m.b1 .+ m.w1 * mat(x))\n",
    "end\n",
    "\n",
    "function (m::TwoLayerMLP)(x,labels; γ=GAMMA) # loss\n",
    "    y1 = relu.(m.b1 .+ m.w1 * mat(x))\n",
    "    y2 = m.b2 .+ m.w2 * y1\n",
    "    J = nll(y2,labels)  # per instance average negative log likelihood loss\n",
    "    g = sumlogdet(y1,labels,m,update=true)\n",
    "    return J + γ * g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization function and its derivative; assume batchsize=1 for now\n",
    "function sumlogdet(y,labels,m; λ=LAMBDA, update=false)\n",
    "#    global B,B2,β,μ,y0,z,ξ,g # DBG\n",
    "    # TODO: handle batchsize > 1\n",
    "    @assert length(labels)==1 \"Batchsize > 1 not implemented yet.\"\n",
    "    \n",
    "    β = labels[1]   # β(n) class label for the nth sample\n",
    "    μ = m.μ[:,β:β]  # μ[β(n)](n-1) exponentially weighted mean of class β(n) before the nth sample\n",
    "    B = m.B[:,:,β]  # B[β(n)](n-1) exponentially weighted inverse covariance matrix of class β(n) before the nth sample\n",
    "    \n",
    "    y0 = y - μ      # ybar[L-1](n) the centralized feature vector\n",
    "    z = B * y0      # unscaled gradient\n",
    "    ξ = 1 / ((1/(1-λ)) + (y0' * B * y0)[1])  # gradient scaling\n",
    "    B2 = (1/λ)*(B - z*z'*ξ)  # updated inverse covariance matrix\n",
    "    g = m.g[1] + logdet(B) - logdet(B2)  # updated -sumlogdet(B)\n",
    "\n",
    "    if training()  # Store gradient if differentiating\n",
    "        m.∇g .= 2 * ξ * z\n",
    "    end\n",
    "    \n",
    "    if update      # Update state if specified\n",
    "        m.g[1] = g\n",
    "        m.B[:,:,β] .= B2\n",
    "        m.μ[:,β:β] .= λ * μ + (1-λ) * y\n",
    "    end\n",
    "\n",
    "    return g\n",
    "end\n",
    "\n",
    "function sumlogdetback(m)\n",
    "    m.∇g\n",
    "end\n",
    "\n",
    "@primitive sumlogdet(y1,y,m;o...)  sumlogdetback(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check gradients\n",
    "using AutoGrad: @gcheck\n",
    "m = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "x,y = first(dtrn)\n",
    "@gcheck m(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check gradients\n",
    "y1 = Param(relu.(m.b1 .+ m.w1 * mat(x)))\n",
    "@gcheck sumlogdet(y1,y,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44e-05  100.00%┣███████████████████████████████████┫ 60000/60000 [01:52/01:52, 533.53i/s]\n"
     ]
    }
   ],
   "source": [
    "# Train model m1 without regularization\n",
    "m1 = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "pred1(x)=m1.b2 .+ m1.w2 * relu.(m1.b1 .+ m1.w1 * mat(x))\n",
    "loss1(x,y)=nll(pred1(x), y)\n",
    "trn100,tst100= mnistdata(xtype=ARRAY, batchsize=100)\n",
    "progress!(adam(loss1,repeat(trn100,100)))\n",
    "accuracy(pred1,trn100),accuracy(pred1,tst100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm.(μ) = [19.9217, 27.9571, 30.2238, 26.5543, 26.1994, 26.1632, 26.3726, 25.2343, 25.3175, 34.8589]\n",
      "logdet.(C) = [-57.7199, 73.4593, 61.9336, 28.543, 58.8477, 25.8958, 33.7952, 55.8698, 32.4212, 31.5816]\n",
      "logdet.(B) = [57.7199, -73.4593, -61.9336, -28.543, -58.8477, -25.8958, -33.7952, -55.8698, -32.4212, -31.5816]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean and covariance without regularization\n",
    "(xtrn,ytrn,xtst,ytst) = mnist()\n",
    "x60k = ARRAY(reshape(xtrn,28*28,:))\n",
    "h60k = relu.(m1.b1 .+ m1.w1 * x60k)\n",
    "h = Any[ h60k[:,ytrn.==i] for i in 1:10 ]\n",
    "μ = Any[ mean(h[i],dims=2) for i in 1:10 ]\n",
    "C = Any[ (h0=h[i] .- μ[i]; h0 * h0' / size(h0,2)) for i in 1:10 ]\n",
    "B = Any[ inv(C[i]) for i in 1:10 ]\n",
    "@show norm.(μ)\n",
    "@show logdet.(C)\n",
    "@show logdet.(B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "-1.55e+00  0.01%┣                                         ┫ 1/10000 [00:00/08:09, 20.44i/s]\r",
      "-1.47e+00  3.28%┣█▏                                    ┫ 328/10000 [00:01/00:32, 312.19i/s]\r",
      "-1.42e+00  6.84%┣██▌                                   ┫ 684/10000 [00:02/00:30, 333.51i/s]\r",
      "-1.39e+00  10.46%┣███▊                                ┫ 1046/10000 [00:03/00:29, 342.81i/s]\r",
      "-1.36e+00  14.17%┣█████                               ┫ 1417/10000 [00:04/00:29, 349.65i/s]\r",
      "-1.35e+00  17.85%┣██████▍                             ┫ 1785/10000 [00:05/00:28, 353.18i/s]\r",
      "-1.34e+00  21.52%┣███████▋                            ┫ 2152/10000 [00:06/00:28, 355.34i/s]\r",
      "-1.33e+00  25.29%┣█████████                           ┫ 2529/10000 [00:07/00:28, 358.36i/s]\r",
      "-1.32e+00  29.00%┣██████████▍                         ┫ 2900/10000 [00:08/00:28, 359.85i/s]\r",
      "-1.31e+00  32.69%┣███████████▊                        ┫ 3269/10000 [00:09/00:28, 360.85i/s]\r",
      "-1.30e+00  36.28%┣█████████████                       ┫ 3628/10000 [00:10/00:28, 360.65i/s]\r",
      "-1.30e+00  40.02%┣██████████████▍                     ┫ 4002/10000 [00:11/00:28, 361.83i/s]\r",
      "-1.29e+00  43.68%┣███████████████▋                    ┫ 4368/10000 [00:12/00:28, 362.10i/s]\r",
      "-1.29e+00  47.37%┣█████████████████                   ┫ 4737/10000 [00:13/00:28, 362.58i/s]\r",
      "-1.28e+00  51.13%┣██████████████████▍                 ┫ 5113/10000 [00:14/00:28, 363.50i/s]\r",
      "-1.28e+00  54.85%┣███████████████████▋                ┫ 5485/10000 [00:15/00:27, 364.04i/s]\r",
      "-1.28e+00  58.55%┣█████████████████████               ┫ 5855/10000 [00:16/00:27, 364.37i/s]\r",
      "-1.27e+00  62.22%┣██████████████████████▍             ┫ 6222/10000 [00:17/00:27, 364.49i/s]\r",
      "-1.27e+00  65.87%┣███████████████████████▋            ┫ 6587/10000 [00:18/00:27, 364.48i/s]\r",
      "-1.27e+00  69.49%┣█████████████████████████           ┫ 6949/10000 [00:19/00:27, 364.30i/s]\r",
      "-1.27e+00  73.09%┣██████████████████████████▎         ┫ 7309/10000 [00:20/00:27, 364.05i/s]\r",
      "-1.26e+00  76.87%┣███████████████████████████▋        ┫ 7687/10000 [00:21/00:27, 364.68i/s]\r",
      "-1.26e+00  80.58%┣█████████████████████████████       ┫ 8058/10000 [00:22/00:27, 364.95i/s]\r",
      "-1.26e+00  84.34%┣██████████████████████████████▎     ┫ 8434/10000 [00:23/00:27, 365.39i/s]\r",
      "-1.26e+00  88.10%┣███████████████████████████████▋    ┫ 8810/10000 [00:24/00:27, 365.83i/s]\r",
      "-1.26e+00  91.80%┣█████████████████████████████████   ┫ 9180/10000 [00:25/00:27, 365.97i/s]\r",
      "-1.25e+00  95.45%┣██████████████████████████████████▎ ┫ 9545/10000 [00:26/00:27, 365.93i/s]\r",
      "-1.25e+00  99.13%┣███████████████████████████████████▋┫ 9913/10000 [00:27/00:27, 366.00i/s]\r",
      "-1.25e+00  100.00%┣█████████████████████████████████▉┫ 10000/10000 [00:27/00:27, 366.06i/s]\n"
     ]
    }
   ],
   "source": [
    "# Do we converge to the right inv cov with our updates?\n",
    "m1.μ .= initμ(HSIZE,YSIZE)\n",
    "m1.B .= initB(HSIZE,YSIZE)\n",
    "# just compute loss and update μ,B, do not change weights\n",
    "progress!(m1(x,y) for (x,y) in take(dtrn,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(real = 19.921662550809856, pred = 13.828536406381236, diff = 6.1283650774635925)\n",
      "(real = 27.957112791647585, pred = 17.54194278401869, diff = 10.47183825571481)\n",
      "(real = 30.223848099072185, pred = 19.857264495487815, diff = 10.40106992209713)\n",
      "(real = 26.554283326683308, pred = 16.822313098196727, diff = 9.754920931114366)\n",
      "(real = 26.199362447537467, pred = 14.695964602910797, diff = 11.582652584149859)\n",
      "(real = 26.163237587245103, pred = 16.80837921156584, diff = 9.391836152417179)\n",
      "(real = 26.37258752026844, pred = 17.431162006128584, diff = 8.966467061709775)\n",
      "(real = 25.234255806222098, pred = 15.299735244052941, diff = 9.955916646167811)\n",
      "(real = 25.317502304304885, pred = 15.97361696714776, diff = 9.363439789986582)\n",
      "(real = 34.858885282642596, pred = 22.27957592138737, diff = 12.597850480976998)\n"
     ]
    }
   ],
   "source": [
    "# Compare μ\n",
    "for i in 1:10\n",
    "    println((real=norm(μ[i]),pred=norm(m1.μ[:,i]),diff=norm(μ[i]-m1.μ[:,i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(real = 127.58358854028396, pred = 172.15031629690796, diff = 66.30301061572978)\n",
      "(real = 7.078215930093306, pred = 12.859943950804903, diff = 6.328364212340608)\n",
      "(real = 8.284792935381866, pred = 14.003642747773327, diff = 6.232317499641436)\n",
      "(real = 64.91594464678964, pred = 107.57085562264054, diff = 46.079288440718734)\n",
      "(real = 8.704410068496124, pred = 17.736126463600105, diff = 9.519552282459005)\n",
      "(real = 20.93898661955777, pred = 38.85031054020234, diff = 19.270871029529083)\n",
      "(real = 19.817326109905256, pred = 31.73697979969098, diff = 12.960315278752782)\n",
      "(real = 8.76908949311271, pred = 15.740594044692417, diff = 7.559772619780569)\n",
      "(real = 13.117170583006624, pred = 23.84868435150763, diff = 11.521579131182111)\n",
      "(real = 24.252019372716877, pred = 51.597795434523505, diff = 29.897922747894942)\n"
     ]
    }
   ],
   "source": [
    "# Compare B\n",
    "for i in 1:10\n",
    "    println((real=norm(B[i]),pred=norm(m1.B[:,:,i]),diff=norm(B[i]-m1.B[:,:,i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(real = 57.71992034738368, pred = 80.72109893430219)\n",
      "(real = -73.45927850158313, pred = -41.757905414556944)\n",
      "(real = -61.93363597624913, pred = -34.09119813286764)\n",
      "(real = -28.542967439463844, pred = 2.0328763533353187)\n",
      "(real = -58.8476822640747, pred = -19.421990843425476)\n",
      "(real = -25.895756131576373, pred = 5.675230355276158)\n",
      "(real = -33.795214178715895, pred = -7.603199417642858)\n",
      "(real = -55.869844755435146, pred = -24.121762831176305)\n",
      "(real = -32.421167117789686, pred = -2.2190724590249538)\n",
      "(real = -31.58162687406806, pred = -2.1537291232839673)\n"
     ]
    }
   ],
   "source": [
    "# Compare logdet(B)\n",
    "for i in 1:10\n",
    "    println((real=logdet(B[i]),pred=logdet(m1.B[:,:,i])))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUNK below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = mnistdata(xtype=ARRAY,batchsize=60000)\n",
    "length(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.86915974358613e305, 0.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det(B),det(z*z'*ξ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894\n",
       " -147.36544595161894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[logdet(mlp.B[:,:,i]) for i in 1:size(mlp.B,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704.8692515439695, 711.1449552901472)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdet(B),logdet(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64×10 Array{Float64,2}:\n",
       " 0.00496261   0.0459837    0.0645267    …  0.0486146    0.000528384  0.0470241  \n",
       " 0.000158066  0.0615158    0.00209705      0.00182906   0.000214186  0.00959594 \n",
       " 0.0          0.0          0.0             0.0          0.0          0.0        \n",
       " 0.000113193  0.00301375   2.24206e-5      6.63593e-6   2.65391e-5   0.00838022 \n",
       " 0.0          0.0          0.0             0.0          0.0          2.38151e-8 \n",
       " 9.23947e-5   0.0171907    0.000137434  …  0.0033648    0.00053961   0.0133446  \n",
       " 8.78306e-6   0.0140433    0.0106992       0.00625449   0.00307099   0.0602241  \n",
       " 0.000100281  9.24048e-5   4.49226e-5      0.000150243  0.000770539  0.00351912 \n",
       " 0.000707857  0.00310398   0.0136447       0.001852     0.00436781   0.00851628 \n",
       " 8.74099e-5   2.04788e-5   4.0206e-5       1.39807e-5   0.00024543   0.0569637  \n",
       " 0.0868852    0.000464658  2.16367e-5   …  0.00260179   4.693e-5     3.36568e-6 \n",
       " 0.290715     0.00169766   3.07977e-5      0.00347629   5.90167e-5   1.5863e-5  \n",
       " 0.00951098   0.00158502   0.00503079      0.0128916    0.00044472   0.00692951 \n",
       " ⋮                                      ⋱                                       \n",
       " 0.473804     0.0247194    0.00702006      0.000731283  5.36004e-6   0.0        \n",
       " 0.000400136  0.000257671  0.00596981      0.00014845   5.04888e-5   9.28754e-5 \n",
       " 0.000760384  0.00131905   0.00265222      0.00452438   0.0605755    9.30237e-5 \n",
       " 0.139819     0.00326959   3.25224e-6   …  0.000194864  4.10772e-7   0.0        \n",
       " 0.197593     0.0185623    0.00976139      0.00852092   0.00202784   0.000743701\n",
       " 9.8854e-5    0.0187529    0.00125811      0.0109367    0.000966198  0.00221994 \n",
       " 0.0375907    0.00101081   0.00447004      0.00164407   3.77516e-5   0.00186145 \n",
       " 0.264272     0.0125433    0.00874781      0.00536088   0.000134704  0.000478815\n",
       " 0.000696135  0.00422936   0.00244068   …  6.95495e-5   0.000266139  0.0371105  \n",
       " 0.00653013   0.114        0.0159505       0.0173049    0.000200979  0.00590513 \n",
       " 0.0          0.0          0.0             0.0          1.11745e-9   0.0        \n",
       " 0.018757     0.036338     0.00358859      0.00246986   0.000610566  0.0222642  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV[\"COLUMNS\"]=90\n",
    "mlp.μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "-2.95e+03  0.02%┣                                          ┫ 1/5000 [00:00/02:11, 38.19i/s]\r",
      "-2.93e+03  4.86%┣█▉                                     ┫ 243/5000 [00:01/00:21, 236.12i/s]\r",
      "-2.90e+03  10.00%┣███▊                                  ┫ 500/5000 [00:02/00:20, 246.35i/s]\r",
      "-2.86e+03  15.14%┣█████▊                                ┫ 757/5000 [00:03/00:20, 249.63i/s]\r",
      "-2.83e+03  20.32%┣███████▌                             ┫ 1016/5000 [00:04/00:20, 251.82i/s]\r",
      "-2.80e+03  25.28%┣█████████▎                           ┫ 1264/5000 [00:05/00:20, 251.04i/s]\r",
      "-2.78e+03  30.44%┣███████████▎                         ┫ 1522/5000 [00:06/00:20, 252.06i/s]\r",
      "-2.76e+03  35.60%┣█████████████▏                       ┫ 1780/5000 [00:07/00:20, 252.83i/s]\r",
      "-2.75e+03  40.88%┣███████████████▏                     ┫ 2044/5000 [00:08/00:20, 254.06i/s]\r",
      "-2.74e+03  46.04%┣█████████████████                    ┫ 2302/5000 [00:09/00:20, 254.45i/s]\r",
      "-2.73e+03  51.20%┣██████████████████▉                  ┫ 2560/5000 [00:10/00:20, 254.77i/s]\r",
      "-2.72e+03  56.34%┣████████████████████▊                ┫ 2817/5000 [00:11/00:20, 254.94i/s]\r",
      "-2.71e+03  61.48%┣██████████████████████▋              ┫ 3074/5000 [00:12/00:20, 255.09i/s]\r",
      "-2.71e+03  66.70%┣████████████████████████▋            ┫ 3335/5000 [00:13/00:20, 255.52i/s]\r",
      "-2.71e+03  71.90%┣██████████████████████████▌          ┫ 3595/5000 [00:14/00:20, 255.84i/s]\r",
      "-2.70e+03  76.86%┣████████████████████████████▍        ┫ 3843/5000 [00:15/00:20, 255.28i/s]\r",
      "-2.70e+03  81.96%┣██████████████████████████████▎      ┫ 4098/5000 [00:16/00:20, 255.21i/s]\r",
      "-2.70e+03  87.02%┣████████████████████████████████▏    ┫ 4351/5000 [00:17/00:20, 255.08i/s]\r",
      "-2.70e+03  92.22%┣██████████████████████████████████   ┫ 4611/5000 [00:18/00:20, 255.34i/s]\r",
      "-2.70e+03  97.36%┣████████████████████████████████████ ┫ 4868/5000 [00:19/00:20, 255.38i/s]\r",
      "-2.69e+03  100.00%┣████████████████████████████████████┫ 5000/5000 [00:20/00:20, 255.38i/s]\n"
     ]
    }
   ],
   "source": [
    "GAMMA=0.0\n",
    "mlp = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "progress!(mlp.g[1] for x in adam(mlp, take(dtrn,5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68285, 0.6743)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(mlp,dtrn),accuracy(mlp,dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "(x,y) = first(dtrn)\n",
    "mlp(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical gradient check:\n",
    "(x,y) = first(dtrn)\n",
    "m = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "@show y1 = relu.(m.b1 .+ m.w1 * mat(x))\n",
    "p1 = Param(y1)\n",
    "@show J = @diff sumlogdet(p1,y,m)\n",
    "@show grad(J,p1)\n",
    "ϵ = 1e-4\n",
    "for i in 1:length(y1)\n",
    "    y1i = y1[i]\n",
    "    y1[i] = y1i + ϵ\n",
    "    f1 = sumlogdet(y1,y,m)\n",
    "    y1[i] = y1i - ϵ\n",
    "    f2 = sumlogdet(y1,y,m)\n",
    "    println((i,((f1-f2)/2ϵ)))\n",
    "    y1[i] = y1i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AutoGrad: @gcheck\n",
    "@gcheck sumlogdet(Param(y1),y,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = TwoLayerMLP(XSIZE,HSIZE,YSIZE)\n",
    "progress!(adam(mlp, repeat(dtrn,10)))\n",
    "accuracy(mlp,dtrn),accuracy(mlp,dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
